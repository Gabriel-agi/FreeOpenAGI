<!DOCTYPE html>
<html lang="en"> <!-- Default language -->
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <!-- Dynamic Title -->
    <title data-translate="page_title_browser_details">AGI Companion Browser - Details & Demo | Road to Free Open AGI</title>
    <style>
        /* --- Core Styles (Inspired by apps.html for consistency) --- */
        :root {
            --primary: #6e48aa;
            --secondary: #9d50bb;
            --accent: #4776e6;
            --dark: #1a1a2e;
            --light: #f8f9fa;
            --success: #4cc9f0;
            --text: #333;
            --text-light: #f8f9fa;
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
        }

        body {
            background: linear-gradient(135deg, var(--dark), #16213e);
            color: var(--text-light);
            line-height: 1.7; /* Slightly increased for readability */
            overflow-x: hidden;
            min-height: 100vh;
            display: flex;
            flex-direction: column;
        }

        .particles {
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            z-index: -1;
            pointer-events: none;
        }

        .container {
            max-width: 960px; /* Adjusted for optimal reading width */
            margin: 1rem auto 2rem auto; /* Added top margin */
            padding: 2.5rem; /* Increased padding */
            flex-grow: 1;
            background: rgba(255, 255, 255, 0.05);
            border-radius: 15px;
            border: 1px solid rgba(255, 255, 255, 0.1);
            backdrop-filter: blur(5px);
            animation: fadeIn 1s ease-out;
        }

        /* --- Navigation (Copied from apps.html for consistency) --- */
        .main-nav {
            display: flex; align-items: center; gap: 1.5rem; padding: 1rem; margin-bottom: 2rem; flex-wrap: wrap; background: rgba(255,255,255,0.05); border-radius: 10px; border: 1px solid rgba(255,255,255,0.1);
        }
        .main-nav a { color: var(--success); text-decoration: none; font-weight: 500; padding: 0.5rem 1rem; border-radius: 5px; transition: all 0.3s ease; white-space: nowrap; }
        .main-nav a:hover { background: rgba(76, 201, 240, 0.2); transform: translateY(-2px); }
        .language-switcher { margin-left: auto; position: relative; }
        #languageSelect { background: rgba(255,255,255,0.1); color: white; border: 1px solid var(--success); border-radius: 5px; padding: 6px 30px 6px 12px; cursor: pointer; font-size: 0.9rem; appearance: none; -webkit-appearance: none; -moz-appearance: none; background-image: url('data:image/svg+xml;charset=US-ASCII,%3Csvg%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%20width%3D%22292.4%22%20height%3D%22292.4%22%3E%3Cpath%20fill%3D%22%234CC9F0%22%20d%3D%22M287%2069.4a17.6%2017.6%200%200%200-13-5.4H18.4c-5%200-9.3%201.8-12.9%205.4A17.6%2017.6%200%200%200%200%2082.2c0%205%201.8%209.3%205.4%2012.9l128%20127.9c3.6%203.6%207.8%205.4%2012.8%205.4s9.2-1.8%2012.8-5.4L287%2095c3.5-3.5%205.4-7.8%205.4-12.8%200-5-1.9-9.2-5.5-12.8z%22%2F%3E%3C%2Fsvg%3E'); background-repeat: no-repeat; background-position: right 10px center; background-size: 10px auto; transition: background-color 0.3s ease; }
        #languageSelect:hover { background-color: rgba(255,255,255,0.15); }
        #languageSelect option { background: var(--dark); color: var(--text-light); }
        /* --- End Navigation --- */

        /* --- Content Styles --- */
        h1 {
            font-size: 2.8rem; /* Adjusted size */
            text-align: center;
            margin-bottom: 1rem; /* Reduced margin */
            background: linear-gradient(to right, var(--secondary), var(--accent));
            -webkit-background-clip: text;
            background-clip: text;
            color: transparent;
            text-shadow: 0 2px 10px rgba(0,0,0,0.2);
            padding-bottom: 0.5rem;
        }
        .subtitle { /* Added a subtitle style */
            text-align: center;
            font-size: 1.2rem;
            color: var(--success);
            margin-bottom: 3rem;
            opacity: 0.9;
        }
        h2 {
            font-size: 1.8rem; /* Adjusted size */
            color: var(--secondary);
            margin-top: 2.5rem; /* Added space before sections */
            margin-bottom: 1rem;
            padding-bottom: 0.4rem;
            border-bottom: 2px solid var(--accent);
            display: inline-block;
        }
        p { margin-bottom: 1.2rem; }
        a { color: var(--success); text-decoration: none; transition: color 0.3s ease; }
        a:hover { text-decoration: underline; color: var(--light); }

        /* Styling for lists */
        ul, ol {
            margin-left: 1.5rem;
            padding-left: 1rem;
            margin-bottom: 1.2rem;
        }
        li { margin-bottom: 0.6rem; }

        /* Code/Command Highlighting */
        .highlight {
             background-color: rgba(76, 201, 240, 0.15);
             padding: 0.15em 0.5em;
             border-radius: 5px;
             font-family: 'Courier New', Courier, monospace; /* Monospaced font */
             font-size: 0.95em;
             color: var(--success);
             border: 1px solid rgba(76, 201, 240, 0.3);
             white-space: nowrap; /* Prevent wrapping */
        }
        /* Emphasis style */
        .emphasize {
            font-style: italic;
            color: #ccc; /* Lighter emphasis color */
        }

        /* Video container */
        .video-container {
            margin: 2.5rem 0;
            text-align: center;
            position: relative;
            padding-bottom: 56.25%; /* 16:9 Aspect Ratio */
            height: 0;
            overflow: hidden;
            background-color: #000; /* Black background */
            border-radius: 10px;
            box-shadow: 0 10px 25px rgba(0,0,0,0.4);
        }
        .video-container video {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            border-radius: 10px; /* Match container */
            border: none;
        }
        .video-caption { /* Added caption style */
            text-align: center;
            font-style: italic;
            font-size: 0.9rem;
            margin-top: -1.5rem; /* Pull caption closer */
            margin-bottom: 2rem;
            opacity: 0.8;
        }

        /* Buttons / Links */
        .cta-button {
            display: inline-block;
            padding: 0.8rem 1.8rem;
            background: linear-gradient(to right, var(--primary), var(--secondary));
            color: white;
            border-radius: 50px;
            text-decoration: none;
            font-weight: bold;
            margin: 0.5rem;
            transition: transform 0.3s ease, box-shadow 0.3s ease;
            text-align: center;
            border: none;
            cursor: pointer;
        }
        .cta-button:hover {
            transform: translateY(-3px);
            box-shadow: 0 5px 15px rgba(0,0,0,0.3);
            text-decoration: none;
            color: white;
        }
        .button-secondary { /* Added secondary style */
             background: var(--accent);
        }
         .button-secondary:hover {
             background: var(--primary);
         }
        .button-container { /* Center buttons */
            text-align: center;
            margin-top: 2rem;
        }

        /* Back link */
        .back-link {
            display: inline-block; /* Changed display */
            margin-top: 3rem;
            margin-bottom: 1rem; /* Added bottom margin */
            font-weight: bold;
            padding: 0.5rem 1rem;
            border: 1px solid var(--success);
            border-radius: 5px;
            transition: background-color 0.3s ease, color 0.3s ease;
        }
         .back-link:hover {
             background-color: rgba(76, 201, 240, 0.2);
             text-decoration: none;
         }


        /* Footer styles */
        footer {
            text-align: center;
            margin-top: auto;
            padding: 2rem;
            font-size: 0.9rem;
            opacity: 0.7;
            background: rgba(255,255,255,0.02);
        }

        /* Animations */
        @keyframes fadeIn { from { opacity: 0; } to { opacity: 1; } }

        /* Responsive Adjustments */
        @media (max-width: 768px) {
             .container { padding: 1.5rem; }
             h1 { font-size: 2.2rem; }
             .subtitle { font-size: 1.1rem; margin-bottom: 2rem;}
             h2 { font-size: 1.6rem; }
             .main-nav { justify-content: center; gap: 0.8rem; padding: 0.8rem; }
             .main-nav a { padding: 0.4rem 0.8rem; font-size: 0.9rem; }
             .language-switcher { margin-left: 0; margin-top: 1rem; }
             .cta-button { display: block; width: 80%; margin: 0.8rem auto; }
             .back-link { display: block; text-align: center; margin: 2rem auto; }
        }

    </style>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css"> <!-- Font Awesome for potential icons later -->
</head>
<body>
    <div id="particles-js" class="particles"></div>

    <!-- Consistent Navigation Header -->
    <header style="padding: 0 1rem;"> <!-- Added padding to header for nav spacing -->
         <nav class="main-nav">
            <!-- Navigation Links -->
            <a href="index.html" data-translate="nav_home">Road to AGI</a>
            <a href="news.html" data-translate="nav_news">AI News</a>
            <a href="courses.html" data-translate="nav_courses">Courses</a>
            <a href="mission.html" data-translate="nav_mission">Mission</a>
            <a href="games.html" data-translate="nav_games">Games</a>
            <a href="comics.html" data-translate="nav_comics">Comics</a>
            <a href="videos.html" data-translate="nav_videos">Videos</a>
            <a href="apps.html" data-translate="nav_apps">Apps</a>
            <a href="contact.html" data-translate="nav_contact">Contact</a>
            <a href="about.html" data-translate="nav_about">About</a>
            <!-- Language Switcher -->
            <div class="language-switcher">
                <select id="languageSelect">
                    <option value="en">🇬🇧 English</option>
                    <option value="pt">🇧🇷 Português</option>
                    <option value="zh">🇨🇳 中文</option>
                </select>
            </div>
        </nav>
    </header>

    <div class="container">

        <h1 data-translate="browser_details_main_title">AGI Companion Browser</h1>
        <p class="subtitle" data-translate="browser_details_subtitle">Visually Control the Web with your AI Agent on Android</p>

        <p data-translate="browser_details_intro_1">Imagine telling your phone, "Book the usual flight for next Tuesday," or "Summarize the key arguments on this forum page," and having it simply... *happen*. While we're not quite there yet, the AGI Companion Browser is a significant step towards that future – a future where AI agents handle the mundane (and complex) tasks of web interaction for us.</p>

        <p data-translate="browser_details_intro_2">Born from the desire to automate web navigation and escape the endless cycle of clicks and typing, this experimental Android browser empowers advanced AI models to see, understand, and act on web pages, bridging the gap between language commands and visual web reality.</p>

        <h2 data-translate="browser_details_how_title">How It Works: Giving AI Eyes and Hands</h2>

        <p data-translate="browser_details_how_intro">The core concept merges multimodal AI perception with precise action simulation:</p>
        <ol>
            <li data-translate="browser_details_how_step1"><strong>See:</strong> The app captures the current web page visually – providing both a clean screenshot and one overlaid with a numbered grid (like R5C8) to the AI.</li>
            <li data-translate="browser_details_how_step2"><strong>Understand:</strong> You provide a natural language goal (e.g., "Log me in", "Find the latest AI news"). The multimodal AI (currently Google Gemini) analyzes your request alongside the visual context of the screenshots and its own internal memory.</li>
            <li data-translate="browser_details_how_step3"><strong>Plan & Act:</strong> The AI plans the necessary steps and responds with specific, actionable commands. These aren't vague suggestions; they are precise instructions like <span class="highlight">CLICK R7C3</span>, <span class="highlight">TYPE R2C4 :: My Username</span>, <span class="highlight">NAVIGATE https://example.com</span>, or uses <span class="highlight">NOTE :: ...</span> to update its internal checklist and reasoning.</li>
            <li data-translate="browser_details_how_step4"><strong>Execute:</strong> The AGI Companion Browser receives these commands and simulates the corresponding user actions (taps, text input, navigation) directly within the Android WebView component.</li>
            <li data-translate="browser_details_how_step5"><strong>Iterate:</strong> This see-understand-act cycle repeats, allowing the agent to perform complex, multi-step tasks across different pages until your goal is achieved or the interaction concludes.</li>
        </ol>

        <h2 data-translate="browser_details_demo_title">Demo: Autonomous Web Task</h2>

        <p data-translate="browser_details_demo_intro">Words can only explain so much. Watch this short demo where the AGI Companion Browser is asked to find cat videos on Bilibili:</p>

        <div class="video-container">
            <video controls poster="https://via.placeholder.com/800x450/1a1a2e/6e48aa?text=Loading+Demo..." preload="metadata">
                <!-- Ensure AGI-Companion-Browser.mp4 is in the same folder or adjust path -->
                <source src="AGI-Companion-Browser.mp4" type="video/mp4">
                <!-- Fallback Text -->
                <span data-translate="browser_details_video_fallback">Your browser does not support the video tag. View the source on GitHub to learn more!</span>
            </video>
        </div>
        <p class="video-caption" data-translate="browser_details_video_caption">Demo showing navigation, search bar interaction, typing (with a small AI typo!), and clicking video results.</p>

        <p data-translate="browser_details_demo_outro">As the demo shows, the agent successfully navigates, identifies elements, types (albeit imperfectly – demonstrating current AI limitations!), and completes the task. This highlights the incredible potential even at this early stage.</p>

        <h2 data-translate="browser_details_challenges_title">The Development Journey & Challenges</h2>

        <p data-translate="browser_details_challenges_intro">Building this bridge between language, vision, and web action presented numerous fascinating challenges:</p>
        <ul>
            <li data-translate="browser_details_challenge_prompting"><strong>Sophisticated Prompt Engineering:</strong> Designing the master prompt ("System Prompt") was critical. It needs to meticulously guide the AI on interpreting visual grid coordinates, formatting commands flawlessly, reasoning about its actions, and using the <span class="highlight">NOTE ::</span> command as its working memory and checklist.</li>
            <li data-translate="browser_details_challenge_simulation"><strong>Reliable Action Simulation:</strong> Programmatically triggering precise clicks and keystrokes within the Android WebView across diverse website structures required careful handling of coordinates, timing, and event dispatching.</li>
            <li data-translate="browser_details_challenge_context"><strong>Maintaining Context:</strong> For multi-step tasks, ensuring the AI remembers the overall goal, the plan (checklist in its NOTE), and the outcome of its last action based on the *new* screenshot is crucial but complex.</li>
            <li data-translate="browser_details_challenge_visual"><strong>Visual Grounding:</strong> Translating the AI's understanding ("the blue button") into a specific, clickable coordinate (<span class="highlight">R6C2</span>) using the grid overlay is fundamental to the agent's operation.</li>
            <li data-translate="browser_details_challenge_integration"><strong>Robust API Handling:</strong> Managing the asynchronous communication with the external AI API, including encoding/decoding image data, handling network timeouts, and gracefully parsing potentially unexpected responses.</li>
        </ul>

        <h2 data-translate="browser_details_future_title">Current Status & Future Vision</h2>

        <p data-translate="browser_details_future_intro">The AGI Companion Browser is proudly **Open Source (MIT Licensed)** and available for you to explore, build, and experiment with on GitHub. While currently powered by Google Gemini, this is just the beginning:</p>
        <ul>
            <li data-translate="browser_details_future_models"><strong>Multi-Model Future:</strong> Active development is underway to integrate other leading multimodal models, including **Qwen (Alibaba)**, **DeepSeek-VL**, and **Llama** models with visual capabilities. This will provide users with choice and allow leveraging the unique strengths of each architecture.</li>
            <li data-translate="browser_details_future_improvement"><strong>Continuous Refinement:</strong> Both the AI models themselves and the agent's core system architecture are rapidly evolving. Expect significant improvements in reliability, efficiency, and the complexity of tasks the agent can handle. The goal? Near-flawless web automation.</li>
            <li data-translate="browser_details_future_goal"><strong>The Ultimate Assistant?:</strong> Can this evolve into an agent seamlessly managing *all* routine web browsing, or even extending to control desktop applications? While ambitious, the potential is immense. **I anticipate** major leaps perhaps by late 2025 or soon after.</li> <!-- CHANGE HERE -->
        </ul>

        <h2 data-translate="browser_details_mission_title">Connecting to the Road to Free Open AGI</h2>

        <p data-translate="browser_details_mission_text">This browser isn't just a technical demonstration; it embodies the core principles of the **Road to Free Open AGI** project. By developing and openly sharing powerful AI agent tools like this, we aim to democratize access to advanced AI capabilities, foster collaborative innovation, and ensure the benefits of artificial general intelligence are accessible to everyone ethically and openly.</p>

        <h2 data-translate="browser_details_cta_title">Get Involved & Explore!</h2>

        <p data-translate="browser_details_cta_intro">Dive into the future of web interaction! Your feedback, ideas, and contributions are highly encouraged:</p>
        <div class="button-container">
            <a href="https://github.com/Gabriel-agi/agi-companion-browser" target="_blank" class="cta-button" data-translate="browser_details_cta_github">View Code on GitHub</a>
            <a href="https://github.com/Gabriel-agi/agi-companion-browser/issues" target="_blank" class="cta-button button-secondary" data-translate="browser_details_cta_issues">Report Issues / Suggest Features</a>
        </div>
        <p data-translate="browser_details_cta_contact" style="text-align: center; margin-top: 1rem;">Feel free to reach out via the main site's contact options to discuss the project!</p>

        <a href="apps.html" class="back-link" data-translate="browser_back_link">← Back to Open AGI Apps</a>

    </div> <!-- End .container -->

    <!-- Footer -->
    <footer>
        <p data-translate="footer_1">The Road to Free Open AGI Project | Committed to ethical, open artificial intelligence for all</p>
        <p data-translate="footer_2_static">Building tools and experiences for an open AI future.</p>
    </footer>

    <script src="https://cdn.jsdelivr.net/particles.js/2.0.0/particles.min.js"></script>
    <script>
        // Initialize particles.js
        particlesJS("particles-js", { /* --- Particles Config (Same as apps.html) --- */
             "particles": { "number": { "value": 80, "density": { "enable": true, "value_area": 800 } }, "color": { "value": "#9d50bb" }, "shape": { "type": "circle", "stroke": { "width": 0, "color": "#000000" }, "polygon": { "nb_sides": 5 } }, "opacity": { "value": 0.5, "random": false, "anim": { "enable": false, "speed": 1, "opacity_min": 0.1, "sync": false } }, "size": { "value": 3, "random": true, "anim": { "enable": false, "speed": 40, "size_min": 0.1, "sync": false } }, "line_linked": { "enable": true, "distance": 150, "color": "#6e48aa", "opacity": 0.4, "width": 1 }, "move": { "enable": true, "speed": 2, "direction": "none", "random": false, "straight": false, "out_mode": "out", "bounce": false, "attract": { "enable": false, "rotateX": 600, "rotateY": 1200 } } }, "interactivity": { "detect_on": "canvas", "events": { "onhover": { "enable": true, "mode": "grab" }, "onclick": { "enable": true, "mode": "push" }, "resize": true }, "modes": { "grab": { "distance": 140, "line_linked": { "opacity": 1 } }, "bubble": { "distance": 400, "size": 40, "duration": 2, "opacity": 8, "speed": 3 }, "repulse": { "distance": 200, "duration": 0.4 }, "push": { "particles_nb": 4 }, "remove": { "particles_nb": 2 } } }, "retina_detect": true
        });

        // --- TRANSLATION SCRIPT ---
        const translations = {
            // =================== ENGLISH (en) ===================
            en: {
                // --- Meta ---
                "page_title_browser_details": "AGI Companion Browser - Details & Demo | Road to Free Open AGI",
                // --- Navigation (Copied from apps.html) ---
                "nav_home": "Road to AGI", "nav_news": "AI News", "nav_courses": "Courses", "nav_mission": "Mission", "nav_games": "Games", "nav_comics": "Comics", "nav_videos": "Videos", "nav_apps": "Apps", "nav_contact": "Contact", "nav_about": "About",
                // --- Page Content ---
                "browser_details_main_title": "AGI Companion Browser",
                "browser_details_subtitle": "Visually Control the Web with your AI Agent on Android",
                "browser_details_intro_1": "Imagine telling your phone, \"Book the usual flight for next Tuesday,\" or \"Summarize the key arguments on this forum page,\" and having it simply... *happen*. While we're not quite there yet, the AGI Companion Browser is a significant step towards that future – a future where AI agents handle the mundane (and complex) tasks of web interaction for us.",
                "browser_details_intro_2": "Born from the desire to automate web navigation and escape the endless cycle of clicks and typing, this experimental Android browser empowers advanced AI models to see, understand, and act on web pages, bridging the gap between language commands and visual web reality.",
                "browser_details_how_title": "How It Works: Giving AI Eyes and Hands",
                "browser_details_how_intro": "The core concept merges multimodal AI perception with precise action simulation:",
                "browser_details_how_step1": "<strong>See:</strong> The app captures the current web page visually – providing both a clean screenshot and one overlaid with a numbered grid (like R5C8) to the AI.",
                "browser_details_how_step2": "<strong>Understand:</strong> You provide a natural language goal (e.g., \"Log me in\", \"Find the latest AI news\"). The multimodal AI (currently Google Gemini) analyzes your request alongside the visual context of the screenshots and its own internal memory.",
                "browser_details_how_step3": "<strong>Plan & Act:</strong> The AI plans the necessary steps and responds with specific, actionable commands. These aren't vague suggestions; they are precise instructions like <span class=\"highlight\">CLICK R7C3</span>, <span class=\"highlight\">TYPE R2C4 :: My Username</span>, <span class=\"highlight\">NAVIGATE https://example.com</span>, or uses <span class=\"highlight\">NOTE :: ...</span> to update its internal checklist and reasoning.",
                "browser_details_how_step4": "<strong>Execute:</strong> The AGI Companion Browser receives these commands and simulates the corresponding user actions (taps, text input, navigation) directly within the Android WebView component.",
                "browser_details_how_step5": "<strong>Iterate:</strong> This see-understand-act cycle repeats, allowing the agent to perform complex, multi-step tasks across different pages until your goal is achieved or the interaction concludes.",
                "browser_details_demo_title": "Demo: Autonomous Web Task",
                "browser_details_demo_intro": "Words can only explain so much. Watch this short demo where the AGI Companion Browser is asked to find cat videos on Bilibili:",
                "browser_details_video_fallback": "Your browser does not support the video tag. View the source on GitHub to learn more!",
                "browser_details_video_caption": "Demo showing navigation, search bar interaction, typing (with a small AI typo!), and clicking video results.",
                "browser_details_demo_outro": "As the demo shows, the agent successfully navigates, identifies elements, types (albeit imperfectly – demonstrating current AI limitations!), and completes the task. This highlights the incredible potential even at this early stage.",
                "browser_details_challenges_title": "The Development Journey & Challenges",
                "browser_details_challenges_intro": "Building this bridge between language, vision, and web action presented numerous fascinating challenges:",
                "browser_details_challenge_prompting": "<strong>Sophisticated Prompt Engineering:</strong> Designing the master prompt (\"System Prompt\") was critical. It needs to meticulously guide the AI on interpreting visual grid coordinates, formatting commands flawlessly, reasoning about its actions, and using the <span class=\"highlight\">NOTE ::</span> command as its working memory and checklist.",
                "browser_details_challenge_simulation": "<strong>Reliable Action Simulation:</strong> Programmatically triggering precise clicks and keystrokes within the Android WebView across diverse website structures required careful handling of coordinates, timing, and event dispatching.",
                "browser_details_challenge_context": "<strong>Maintaining Context:</strong> For multi-step tasks, ensuring the AI remembers the overall goal, the plan (checklist in its NOTE), and the outcome of its last action based on the *new* screenshot is crucial but complex.",
                "browser_details_challenge_visual": "<strong>Visual Grounding:</strong> Translating the AI's understanding (\"the blue button\") into a specific, clickable coordinate (<span class=\"highlight\">R6C2</span>) using the grid overlay is fundamental to the agent's operation.",
                "browser_details_challenge_integration": "<strong>Robust API Handling:</strong> Managing the asynchronous communication with the external AI API, including encoding/decoding image data, handling network timeouts, and gracefully parsing potentially unexpected responses.",
                "browser_details_future_title": "Current Status & Future Vision",
                "browser_details_future_intro": "The AGI Companion Browser is proudly **Open Source (MIT Licensed)** and available for you to explore, build, and experiment with on GitHub. While currently powered by Google Gemini, this is just the beginning:",
                "browser_details_future_models": "<strong>Multi-Model Future:</strong> Active development is underway to integrate other leading multimodal models, including **Qwen (Alibaba)**, **DeepSeek-VL**, and **Llama** models with visual capabilities. This will provide users with choice and allow leveraging the unique strengths of each architecture.",
                "browser_details_future_improvement": "<strong>Continuous Refinement:</strong> Both the AI models themselves and the agent's core system architecture are rapidly evolving. Expect significant improvements in reliability, efficiency, and the complexity of tasks the agent can handle. The goal? Near-flawless web automation.",
                "browser_details_future_goal": "<strong>The Ultimate Assistant?:</strong> Can this evolve into an agent seamlessly managing *all* routine web browsing, or even extending to control desktop applications? While ambitious, the potential is immense. **I anticipate** major leaps perhaps by late 2025 or soon after.", // UPDATED HERE
                "browser_details_mission_title": "Connecting to the Road to Free Open AGI",
                "browser_details_mission_text": "This browser isn't just a technical demonstration; it embodies the core principles of the **Road to Free Open AGI** project. By developing and openly sharing powerful AI agent tools like this, we aim to democratize access to advanced AI capabilities, foster collaborative innovation, and ensure the benefits of artificial general intelligence are accessible to everyone ethically and openly.",
                "browser_details_cta_title": "Get Involved & Explore!",
                "browser_details_cta_intro": "Dive into the future of web interaction! Your feedback, ideas, and contributions are highly encouraged:",
                "browser_details_cta_github": "View Code on GitHub",
                "browser_details_cta_issues": "Report Issues / Suggest Features",
                "browser_details_cta_contact": "Feel free to reach out via the main site's contact options to discuss the project!",
                "browser_back_link": "← Back to Open AGI Apps",
                // --- Footer (Copied from apps.html) ---
                "footer_1": "The Road to Free Open AGI Project | Committed to ethical, open artificial intelligence for all",
                "footer_2_static": "Building tools and experiences for an open AI future."
            },
            // =================== PORTUGUESE (pt) ===================
            pt: {
                 // --- Meta ---
                "page_title_browser_details": "AGI Companion Browser - Detalhes & Demo | Caminho para AGI Gratuita e Aberta",
                 // --- Navigation ---
                "nav_home": "Caminho para AGI", "nav_news": "Notícias de IA", "nav_courses": "Cursos", "nav_mission": "Missão", "nav_games": "Jogos", "nav_comics": "Quadrinhos", "nav_videos": "Vídeos", "nav_apps": "Aplicativos", "nav_contact": "Contato", "nav_about": "Sobre",
                 // --- Page Content ---
                "browser_details_main_title": "AGI Companion Browser",
                "browser_details_subtitle": "Controle a Web Visualmente com seu Agente de IA no Android",
                "browser_details_intro_1": "Imagine dizer ao seu celular: \"Reserve o voo habitual para a próxima terça-feira\" ou \"Resuma os principais argumentos nesta página do fórum\", e isso simplesmente... *acontecer*. Embora ainda não estejamos lá, o AGI Companion Browser é um passo significativo em direção a esse futuro – um futuro onde agentes de IA lidam com as tarefas mundanas (e complexas) da interação na web por nós.",
                "browser_details_intro_2": "Nascido do desejo de automatizar a navegação na web e escapar do ciclo interminável de cliques e digitação, este navegador experimental para Android capacita modelos avançados de IA multimodal a ver, entender e agir em páginas da web, preenchendo a lacuna entre comandos de linguagem e a realidade visual da web.",
                "browser_details_how_title": "Como Funciona: Dando Olhos e Mãos à IA",
                "browser_details_how_intro": "O conceito central mescla a percepção de IA multimodal com a simulação precisa de ações:",
                "browser_details_how_step1": "<strong>Ver:</strong> O aplicativo captura visualmente a página da web atual – fornecendo tanto uma captura de tela limpa quanto uma sobreposta com uma grade numerada (como R5C8) para a IA.",
                "browser_details_how_step2": "<strong>Entender:</strong> Você fornece um objetivo em linguagem natural (ex: \"Faça meu login\", \"Encontre as últimas notícias de IA\"). A IA multimodal (atualmente Google Gemini) analisa sua solicitação juntamente com o contexto visual das capturas de tela e sua própria memória interna.",
                "browser_details_how_step3": "<strong>Planejar & Agir:</strong> A IA planeja as etapas necessárias e responde com comandos específicos e acionáveis. Não são sugestões vagas; são instruções precisas como <span class=\"highlight\">CLICK R7C3</span>, <span class=\"highlight\">TYPE R2C4 :: MeuUsuario</span>, <span class=\"highlight\">NAVIGATE https://exemplo.com</span>, ou usa <span class=\"highlight\">NOTE :: ...</span> para atualizar sua lista de verificação interna e raciocínio.",
                "browser_details_how_step4": "<strong>Executar:</strong> O AGI Companion Browser recebe esses comandos e simula as ações do usuário correspondentes (toques, entrada de texto, navegação) diretamente dentro do componente WebView do Android.",
                "browser_details_how_step5": "<strong>Iterar:</strong> Este ciclo ver-entender-agir se repete, permitindo que o agente execute tarefas complexas de várias etapas em diferentes páginas até que seu objetivo seja alcançado ou a interação seja concluída.",
                "browser_details_demo_title": "Demonstração: Tarefa Web Autônoma",
                "browser_details_demo_intro": "Palavras só podem explicar até certo ponto. Assista a esta curta demonstração onde o AGI Companion Browser é solicitado a encontrar vídeos de gatos no Bilibili:",
                "browser_details_video_fallback": "Seu navegador não suporta a tag de vídeo. Veja o código fonte no GitHub para saber mais!",
                "browser_details_video_caption": "Demonstração mostrando navegação, interação com barra de busca, digitação (com um pequeno erro de digitação da IA!) e clique nos resultados de vídeo.",
                "browser_details_demo_outro": "Como a demonstração mostra, o agente navega com sucesso, identifica elementos, digita (embora imperfeitamente – demonstrando as limitações atuais da IA!) e completa a tarefa. Isso destaca o incrível potencial mesmo nesta fase inicial.",
                "browser_details_challenges_title": "A Jornada de Desenvolvimento & Desafios",
                "browser_details_challenges_intro": "Construir esta ponte entre linguagem, visão e ação na web apresentou inúmeros desafios fascinantes:",
                "browser_details_challenge_prompting": "<strong>Engenharia de Prompt Sofisticada:</strong> Projetar o prompt mestre (\"System Prompt\") foi crucial. Ele precisa guiar meticulosamente a IA na interpretação das coordenadas visuais da grade, formatar comandos impecavelmente, raciocinar sobre suas ações e usar o comando <span class=\"highlight\">NOTE ::</span> como sua memória de trabalho e lista de verificação.",
                "browser_details_challenge_simulation": "<strong>Simulação de Ação Confiável:</strong> Acionar programaticamente cliques e pressionamentos de tecla precisos dentro do WebView do Android em diversas estruturas de sites exigiu um manuseio cuidadoso de coordenadas, tempo e despacho de eventos.",
                "browser_details_challenge_context": "<strong>Manutenção de Contexto:</strong> Para tarefas de várias etapas, garantir que a IA se lembre do objetivo geral, do plano (lista de verificação em seu NOTE) e do resultado de sua última ação com base na *nova* captura de tela é crucial, mas complexo.",
                "browser_details_challenge_visual": "<strong>Ancoragem Visual:</strong> Traduzir o entendimento da IA (\"o botão azul\") em uma coordenada específica e clicável (<span class=\"highlight\">R6C2</span>) usando la sobreposição de grade é fundamental para a operação do agente.",
                "browser_details_challenge_integration": "<strong>Manuseio Robusto de API:</strong> Gerenciar a comunicação assíncrona com a API externa da IA, incluindo codificação/decodificação de dados de imagem, tratamento de tempos limite de rede e análise graciosa de respostas potencialmente inesperadas.",
                "browser_details_future_title": "Status Atual & Visão Futura",
                "browser_details_future_intro": "O AGI Companion Browser é orgulhosamente **Código Aberto (Licença MIT)** e está disponível para você explorar, construir e experimentar no GitHub. Embora atualmente alimentado pelo Google Gemini, este é apenas o começo:",
                "browser_details_future_models": "<strong>Futuro Multi-Modelo:</strong> O desenvolvimento ativo está em andamento para integrar outros modelos multimodais líderes, incluindo modelos **Qwen (Alibaba)**, **DeepSeek-VL** e **Llama** com capacidades visuais. Isso fornecerá aos usuários opções e permitirá alavancar os pontos fortes únicos de cada arquitetura.",
                "browser_details_future_improvement": "<strong>Refinamento Contínuo:</strong> Tanto os próprios modelos de IA quanto a arquitetura central do sistema do agente estão evoluindo rapidamente. Espere melhorias significativas na confiabilidade, eficiência e na complexidade das tarefas que o agente pode lidar. O objetivo? Automação web quase impecável.",
                "browser_details_future_goal": "<strong>O Assistente Definitivo?:</strong> Isso pode evoluir para um agente gerenciando perfeitamente *toda* a navegação web rotineira, ou mesmo estendendo-se para controlar aplicativos de desktop? Embora ambicioso, o potencial é imenso. **Eu antecipo** grandes saltos talvez no final de 2025 ou logo depois.", // UPDATED HERE
                "browser_details_mission_title": "Conectando ao Caminho para AGI Gratuita e Aberta",
                "browser_details_mission_text": "Este navegador não é apenas uma demonstração técnica; ele incorpora os princípios centrais do projeto **Caminho para AGI Gratuita e Aberta**. Ao desenvolver e compartilhar abertamente ferramentas poderosas de agente de IA como esta, pretendemos democratizar o acesso a capacidades avançadas de IA, fomentar a inovação colaborativa e garantir que os benefícios da inteligência artificial geral sejam acessíveis a todos de forma ética e aberta.",
                "browser_details_cta_title": "Envolva-se & Explore!",
                "browser_details_cta_intro": "Mergulhe no futuro da interação na web! Seu feedback, ideias e contribuições são muito encorajados:",
                "browser_details_cta_github": "Ver Código no GitHub",
                "browser_details_cta_issues": "Relatar Problemas / Sugerir Recursos",
                "browser_details_cta_contact": "Sinta-se à vontade para entrar em contato através das opções de contato do site principal para discutir o projeto!",
                "browser_back_link": "← Voltar para Aplicativos Open AGI",
                 // --- Footer ---
                "footer_1": "O Projeto Caminho para AGI Gratuita e Aberta | Comprometido com inteligência artificial ética e aberta para todos",
                "footer_2_static": "Construindo ferramentas e experiências para um futuro de IA aberta."
            },
            // =================== CHINESE (zh) ===================
            zh: {
                 // --- Meta ---
                "page_title_browser_details": "AGI Companion 浏览器 - 详情与演示 | 通往自由开放AGI之路",
                 // --- Navigation ---
                "nav_home": "通往AGI之路", "nav_news": "AI新闻", "nav_courses": "课程", "nav_mission": "使命", "nav_games": "游戏", "nav_comics": "漫画", "nav_videos": "视频", "nav_apps": "应用", "nav_contact": "联系", "nav_about": "关于",
                 // --- Page Content ---
                "browser_details_main_title": "AGI Companion 浏览器",
                "browser_details_subtitle": "在 Android 上用您的 AI 代理可视化地控制网页",
                "browser_details_intro_1": "想象一下，告诉您的手机：“预订下周二的常用航班”，或者“总结这个论坛页面的主要论点”，然后它就简单地……*完成了*。虽然我们还没完全达到那个程度，但 AGI Companion 浏览器是向那个未来迈出的重要一步——一个 AI 代理为我们处理繁琐（且复杂）的网页交互任务的未来。",
                "browser_details_intro_2": "源于自动化网页导航、摆脱无休止点击和输入的渴望，这款实验性的 Android 浏览器使先进的 AI 模型能够观察、理解网页并采取行动，弥合了语言命令与可视化网页现实之间的鸿沟。",
                "browser_details_how_title": "工作原理：赋予 AI 眼睛和双手",
                "browser_details_how_intro": "核心概念融合了多模态 AI 感知与精确的动作模拟：",
                "browser_details_how_step1": "<strong>观察：</strong> 应用可视化地捕获当前网页——向 AI 提供干净的屏幕截图和覆盖了编号网格（如 R5C8）的屏幕截图。",
                "browser_details_how_step2": "<strong>理解：</strong> 您提供一个自然语言目标（例如，“帮我登录”，“查找最新的 AI 新闻”）。多模态 AI（目前是 Google Gemini）结合屏幕截图的视觉上下文和其内部记忆来分析您的请求。",
                "browser_details_how_step3": "<strong>规划与行动：</strong> AI 规划必要的步骤并以特定的、可操作的命令进行响应。这些不是模糊的建议；它们是精确的指令，如 <span class=\"highlight\">CLICK R7C3</span>、<span class=\"highlight\">TYPE R2C4 :: 我的用户名</span>、<span class=\"highlight\">NAVIGATE https://example.com</span>，或使用 <span class=\"highlight\">NOTE :: ...</span> 来更新其内部清单和推理。",
                "browser_details_how_step4": "<strong>执行：</strong> AGI Companion 浏览器接收这些命令，并在 Android WebView 组件内直接模拟相应的用户操作（点击、文本输入、导航）。",
                "browser_details_how_step5": "<strong>迭代：</strong> 这个观察-理解-行动的循环重复进行，使代理能够在不同页面上执行复杂的多步骤任务，直到您的目标完成或交互结束。",
                "browser_details_demo_title": "演示：自主网页任务",
                "browser_details_demo_intro": "语言难以完全解释。观看这个简短的演示，其中 AGI Companion 浏览器被要求在 Bilibili 上查找猫咪视频：",
                "browser_details_video_fallback": "您的浏览器不支持视频标签。请在 GitHub 上查看源代码以了解更多信息！",
                "browser_details_video_caption": "演示展示了导航、搜索栏交互、打字（带有一个小的 AI 输入错误！）以及点击视频结果。",
                "browser_details_demo_outro": "正如演示所示，代理成功地导航、识别元素、打字（尽管不完美——展示了当前 AI 的局限性！）并完成了任务。这突显了即使在早期阶段也具有的巨大潜力。",
                "browser_details_challenges_title": "开发历程与挑战",
                "browser_details_challenges_intro": "在语言、视觉和网络行为之间架起这座桥梁，带来了许多有趣的挑战：",
                "browser_details_challenge_prompting": "<strong>复杂的提示工程：</strong> 设计主提示（“系统提示”）至关重要。它需要细致地指导 AI 如何解释视觉网格坐标、完美地格式化命令、推理其行为，并将 <span class=\"highlight\">NOTE ::</span> 命令用作其工作记忆和清单。",
                "browser_details_challenge_simulation": "<strong>可靠的动作模拟：</strong> 在 Android WebView 中，跨不同的网站结构以编程方式触发精确的点击和按键，需要仔细处理坐标、时间和事件分派。",
                "browser_details_challenge_context": "<strong>维护上下文：</strong> 对于多步骤任务，确保 AI 记住总体目标、计划（在其 NOTE 中的清单）以及基于*新*屏幕截图的上一步操作的结果至关重要，但也非常复杂。",
                "browser_details_challenge_visual": "<strong>视觉定位：</strong> 使用网格覆盖将 AI 的理解（“蓝色按钮”）转化为特定的、可点击的坐标（<span class=\"highlight\">R6C2</span>）是代理操作的基础。",
                "browser_details_challenge_integration": "<strong>稳健的 API 处理：</strong> 管理与外部 AI API 的异步通信，包括编码/解码图像数据、处理网络超时以及优雅地解析潜在的意外响应。",
                "browser_details_future_title": "当前状态与未来展望",
                "browser_details_future_intro": "AGI Companion 浏览器自豪地 **开源（MIT 许可证）**，您可以在 GitHub 上探索、构建和实验。虽然目前由 Google Gemini 提供支持，但这仅仅是个开始：",
                "browser_details_future_models": "<strong>多模型的未来：</strong> 正在积极开发以集成其他领先的多模态模型，包括具有视觉能力的 **Qwen（通义千问）**、**DeepSeek-VL** 和 **Llama** 模型。这将为用户提供选择，并允许利用每种架构的独特优势。",
                "browser_details_future_improvement": "<strong>持续改进：</strong> AI 模型本身和代理的核心系统架构都在快速发展。预计在可靠性、效率以及代理能够处理的任务复杂性方面将有显著提升。目标？近乎完美的网页自动化。",
                "browser_details_future_goal": "<strong>终极助手？：</strong> 这能否演变成一个无缝管理*所有*常规网页浏览的代理，甚至扩展到控制桌面应用程序？虽然雄心勃勃，但潜力巨大。**我预计**可能在 2025 年底或之后不久实现重大飞跃。", // UPDATED HERE
                "browser_details_mission_title": "连接到通往自由开放AGI之路",
                "browser_details_mission_text": "这款浏览器不仅仅是一个技术演示；它体现了 **通往自由开放AGI之路** 项目的核心原则。通过开发和公开分享像这样的强大 AI 代理工具，我们旨在普及对先进 AI 功能的访问，促进协作创新，并确保通用人工智能的好处能够以道德和开放的方式惠及所有人。",
                "browser_details_cta_title": "参与进来 & 探索！",
                "browser_details_cta_intro": "潜入网页交互的未来！我们非常鼓励您的反馈、想法和贡献：",
                "browser_details_cta_github": "在 GitHub 上查看代码",
                "browser_details_cta_issues": "报告问题 / 建议功能",
                "browser_details_cta_contact": "欢迎通过主站点的联系方式讨论项目！",
                "browser_back_link": "← 返回开放AGI应用",
                 // --- Footer ---
                "footer_1": "自由开放AGI之路项目 | 致力于为所有人提供道德、开放的人工智能",
                "footer_2_static": "为开放AI的未来构建工具和体验。"
            }
        };

        // --- Language management functions (Keep As Is) ---
        function getStoredLanguage() {
             const storedLang = localStorage.getItem('userLanguage');
             if (storedLang && translations[storedLang]) return storedLang;
             const browserLang = navigator.language || navigator.userLanguage;
             if (browserLang.startsWith('pt')) return 'pt';
             if (browserLang.startsWith('zh')) return 'zh';
             return 'en'; // Default to English
        }

        function setLanguage(lang) {
             if (!translations[lang]) lang = 'en'; // Fallback to English
             localStorage.setItem('userLanguage', lang);
             document.documentElement.lang = lang; // Set lang attribute on <html>
             translatePage(lang);
        }

        function translatePage(lang) {
            if (!translations[lang]) lang = 'en'; // Fallback
            const langSelect = document.getElementById('languageSelect');
            if (langSelect) langSelect.value = lang; // Update dropdown

            // Translate page title
            const pageTitleElement = document.querySelector('title[data-translate]'); // General selector
            if (pageTitleElement) {
                 const key = pageTitleElement.getAttribute('data-translate');
                 if (translations[lang][key]) {
                     pageTitleElement.textContent = translations[lang][key];
                 }
            }


            // Translate all elements with data-translate attribute
            document.querySelectorAll('[data-translate]').forEach(el => {
                if (el.tagName === 'TITLE') return; // Skip title tag again just in case
                const key = el.getAttribute('data-translate');
                if (translations[lang] && translations[lang][key]) {
                     // Use innerHTML to allow HTML tags within translations (like <strong>)
                     el.innerHTML = translations[lang][key];
                } else {
                     // Optional: Log missing keys
                     // console.warn(`Missing translation key: ${key} for language: ${lang}`);
                }
            });
        }

        // Run on page load
        document.addEventListener('DOMContentLoaded', function() {
            const initialLang = getStoredLanguage();
            setLanguage(initialLang); // Apply initial language

            // Set up language switcher event listener
            const langSelect = document.getElementById('languageSelect');
            if (langSelect) {
                langSelect.addEventListener('change', (e) => {
                    setLanguage(e.target.value);
                });
            }

            // Fade in animation trigger (optional)
            const container = document.querySelector('.container');
            if (container) {
                 container.style.opacity = '0';
                 setTimeout(() => { container.style.opacity = '1'; }, 100); // Simple fade-in
            }

        }); // End DOMContentLoaded
    </script>
</body>
</html>
